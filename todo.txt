============================================================
File: runner.py, Line: 26

    def create_optimizers(self):
        # TODO: Need to pass other params like: momentum, weight_decay, etc...
        optimizer_dict = {}
        for network_name, network in self.network.networks.items():
============================================================

============================================================
File: runner.py, Line: 50
        losses, meta = self.agent.update(self.network, self.replay_buffer, self.agent.config, self.env)
        for loss, optim in zip(losses, self.optimizers.values()):
            # TODO: This assumes the losses are returned in the same order as the optimizers are defined, this shoudn't matter
            loss.backward()
            optim.step()
============================================================

============================================================
File: runner.py, Line: 56

    def train(self):
        # TODO: This is going to be DQN specific at first, to be fixed later
        scores = []
        for episode in range(self.agent.config["training"]["episodes"]):
============================================================

============================================================
File: builder.py, Line: 9

def builder(config: List[Dict[str, dict[str, Any]]], python: List[str]):
    # TODO: Validate the configuration, Use the validate_config() function in config_parser.py
    
    # Turns the string config values into the actual classes
============================================================

============================================================
File: nn_models.py, Line: 91
        means, variances, mixture_coef = self.mdn(lstm_out[0])

        # TODO: Implement correct sampling for MDN
        return mdn_out[0]

============================================================

============================================================
File: nn_models.py, Line: 96
class LSTMCell:
    def __init__(self, input_size, hidden_size):
        # TODO: These weights can be unified, which requires fewer matmuls, find out how it's equivelant to this
        weights = lambda: (Tensor.uniform(input_size, hidden_size),
                           Tensor.uniform(hidden_size, hidden_size),
============================================================

============================================================
File: replay_buffer.py, Line: 4
from collections import namedtuple

# TODO: This is a hack that needs to be rewritten
implemented_envs = ["CarRacing-V2"]

============================================================

